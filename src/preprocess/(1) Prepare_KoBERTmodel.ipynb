{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1667483024903,"user":{"displayName":"김정도","userId":"07172066946536821207"},"user_tz":-540},"id":"dnxDGNiBllRi","outputId":"2c1b1abf-321c-4dc4-80d7-06c863e1724d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}],"source":["import sys\n","sys.version"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XhkeIiv-pGB2"},"outputs":[],"source":["!pip install mxnet\n","!pip install gluonnlp pandas tqdm\n","!pip install sentencepiece\n","!pip install transformers==3.0.2\n","\n","# CUDA 11.1\n","!pip install torch==1.10.1+cu102 torchvision==0.11.2+cu102 torchaudio==0.10.1 -f https://download.pytorch.org/whl/cu102/torch_stable.html\n","\n","#깃허브에서 KoBERT 파일 로드\n","!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v6z3sPxkrmOn"},"outputs":[],"source":["import torch\n","from torch import nn # 파이토치 신경망 라이브러리\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import gluonnlp as nlp\n","import numpy as np\n","from tqdm import tqdm, tqdm_notebook # 데이터 작업 시 커널이 작동중인지 확인할 수 있도록 Progress Bar로 시각화\n","\n","#kobert\n","from kobert.utils import get_tokenizer\n","from kobert.pytorch_kobert import get_pytorch_kobert_model\n","\n","#transformers\n","from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MYBTw455tDZN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667483225290,"user_tz":-540,"elapsed":13991,"user":{"displayName":"김정도","userId":"07172066946536821207"}},"outputId":"0aefdc90-e811-4848-d60d-f132c789c7f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/.cache/kobert_v1.zip[██████████████████████████████████████████████████]\n","/content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece[██████████████████████████████████████████████████]\n"]}],"source":["#GPU 사용\n","device = torch.device(\"cuda:0\")\n","\n","#BERT 모델, Vocabulary 불러오기\n","bertmodel, vocab = get_pytorch_kobert_model()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KPQ8pmCVtIPN"},"outputs":[],"source":["#구글드라이브 연동\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import pandas as pd\n","dialogueSet = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/(AI_Project) unemployedStation/data/한국어_단발성_대화_데이터셋.xlsx')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PVP-lRnht9Uh"},"outputs":[],"source":["dialogueSet.sample(n=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kRojI246uI6f"},"outputs":[],"source":["dialogueSet.loc[(dialogueSet['Emotion'] == \"놀람\"), 'Emotion'] = 1  #놀람 => 1\n","dialogueSet.loc[(dialogueSet['Emotion'] == \"공포\"), 'Emotion'] = 0  #공포 => 0\n","dialogueSet.loc[(dialogueSet['Emotion'] == \"분노\"), 'Emotion'] = 2  #분노 => 2\n","dialogueSet.loc[(dialogueSet['Emotion'] == \"슬픔\"), 'Emotion'] = 3  #슬픔 => 3\n","dialogueSet.loc[(dialogueSet['Emotion'] == \"중립\"), 'Emotion'] = 4  #중립 => 4\n","dialogueSet.loc[(dialogueSet['Emotion'] == \"행복\"), 'Emotion'] = 5  #행복 => 5\n","dialogueSet.loc[(dialogueSet['Emotion'] == \"혐오\"), 'Emotion'] = 6  #혐오 => 6\n","\n","dialogueSet.sample(n=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FFvKEcESuY0j"},"outputs":[],"source":["data_list = []\n","for q, label in zip(dialogueSet['Sentence'], dialogueSet['Emotion'])  :\n","    data = []\n","    data.append(q)\n","    data.append(str(label))\n","\n","    data_list.append(data)\n","\n","print(data_list[0])\n","print(data_list[6000])\n","print(data_list[12000])\n","print(data_list[18000])\n","print(data_list[24000])\n","print(data_list[30000])\n","print(data_list[-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QccgA-DNvJS7"},"outputs":[],"source":["#train & test 데이터로 나누기\n","from sklearn.model_selection import train_test_split\n","\n","state = 548\n","dataset_train, dataset_test = train_test_split(data_list, test_size=0.25, random_state=state)\n","\n","print(len(dataset_train))\n","print(len(dataset_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uw_j612_vXXV"},"outputs":[],"source":["class BERTDataset(Dataset):\n","    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len, pad, pair):\n","        transform = nlp.data.BERTSentenceTransform(\n","            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n","\n","        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n","        self.labels = [np.int32(i[label_idx]) for i in dataset]\n","\n","    def __getitem__(self, i):\n","        return (self.sentences[i] + (self.labels[i], ))\n","\n","    def __len__(self):\n","        return (len(self.labels))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZcL6d966vleH"},"outputs":[],"source":["# Setting parameters\n","max_len = 64\n","batch_size = 64\n","warmup_ratio = 0.1\n","num_epochs = 100\n","max_grad_norm = 1\n","log_interval = 200  # 훈련 로그를 출력할 간격\n","learning_rate =  5e-5  # 과적합의 원인일 수 있음"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Wc3qfMTv3bc"},"outputs":[],"source":["#토큰화\n","tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n","\n","data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n","data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UU9fWPzpv-m2"},"outputs":[],"source":["data_train[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JkQ_QoFqwSts"},"outputs":[],"source":["train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n","test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FaOK0c2jwZXF"},"outputs":[],"source":["class BERTClassifier(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 hidden_size = 768,\n","                 num_classes=7,   ##클래스 수 조정##\n","                 dr_rate=None,\n","                 params=None):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert\n","        self.dr_rate = dr_rate\n","                 \n","        self.classifier = nn.Linear(hidden_size , num_classes)\n","        if dr_rate:\n","            self.dropout = nn.Dropout(p=dr_rate)\n","    \n","    def gen_attention_mask(self, token_ids, valid_length):\n","        attention_mask = torch.zeros_like(token_ids)\n","        for i, v in enumerate(valid_length):\n","            attention_mask[i][:v] = 1\n","        return attention_mask.float()\n","\n","    def forward(self, token_ids, valid_length, segment_ids):\n","        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","        \n","        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n","        if self.dr_rate:\n","            out = self.dropout(pooler)\n","        return self.classifier(out)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qL4Fc8lawf8Q"},"outputs":[],"source":["#BERT 모델 불러오기\n","model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n","\n","#optimizer와 schedule 설정\n","no_decay = ['bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]\n","\n","optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","t_total = len(train_dataloader) * num_epochs\n","warmup_step = int(t_total * warmup_ratio)\n","\n","scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n","\n","#정확도 측정을 위한 함수 정의\n","def calc_accuracy(X,Y):\n","    max_vals, max_indices = torch.max(X, 1)\n","    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n","    return train_acc\n","    \n","train_dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ylj5supMbmF-"},"outputs":[],"source":["class EarlyStopping:\n","    def __init__(self, patience=5):\n","        self.loss = np.inf\n","        self.patience = 0\n","        self.patience_limit = patience\n","        \n","    def step(self, loss):\n","        print('기존 loss: ', self.loss, ', 현재 loss: ', loss)\n","        if self.loss > loss:\n","            self.loss = loss\n","            self.patience = 0\n","            print('loss 갱신.')\n","            return 1\n","\n","        else:\n","            self.patience += 1\n","            print('patience 증가 (', self.patience, '/5)')\n","            return 0\n","    \n","    def is_stop(self):\n","        if self.patience >= self.patience_limit:\n","          print('조기중단.')\n","        return self.patience >= self.patience_limit"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HCOdBpio5m7K"},"outputs":[],"source":["from datetime import date\n","today = date.today().strftime('%y%m%d')\n","\n","# 5번 안에 더 좋아지지 않으면 종료\n","early_stop = EarlyStopping(patience=5)\n","\n","for e in range(num_epochs):\n","    train_acc = 0.0\n","    test_acc = 0.0\n","    loss_store = 0.0\n","    acc_store = 0.0\n","    model.train()\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n","        optimizer.zero_grad()\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","        out = model(token_ids, valid_length, segment_ids)\n","        loss = loss_fn(out, label)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n","        optimizer.step()\n","        scheduler.step()  # Update learning rate schedule\n","        train_acc += calc_accuracy(out, label)\n","        loss_store = loss.data.cpu().numpy()\n","        acc_store = train_acc / (batch_id+1)\n","        if batch_id % log_interval == 0:\n","            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss_store, acc_store))\n","    print(\"epoch {} train acc {}\".format(e+1, acc_store))\n","\n","    model.eval()\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","        out = model(token_ids, valid_length, segment_ids)\n","        loss = loss_fn(out, label)\n","        test_acc += calc_accuracy(out, label)\n","        loss_store = loss.data.cpu().numpy()\n","        acc_store = test_acc / (batch_id+1)\n","    print(\"epoch {} loss {} test acc {}\".format(e+1,loss_store, acc_store))\n","\n","    # 모델 저장 및 조기중단\n","    if early_stop.step(loss_store):\n","      print('모델 갱신.')\n","      torch.save(model, '/content/drive/MyDrive/Colab Notebooks/(AI_Project) unemployedStation/model/bestModel_state{}_epoch{}_acc{:.3f}_{}.h5'.format(state, e+1, acc_store, today))\n","    if early_stop.is_stop():\n","      break"]},{"cell_type":"markdown","metadata":{"id":"XtXdcPFjzfXn"},"source":["## 새로운 문장 테스트"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QO9kszPLpTgm"},"outputs":[],"source":["#토큰화\n","tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n","\n","def predict(predict_sentence):\n","\n","    data = [predict_sentence, '0']\n","    dataset_another = [data]\n","\n","    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n","    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n","    \n","    model.eval()\n","\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","\n","        out = model(token_ids, valid_length, segment_ids)\n","\n","\n","        test_eval=[]\n","        for i in out:\n","            logits=i\n","            logits = logits.detach().cpu().numpy()\n","\n","            if np.argmax(logits) == 0:\n","                test_eval.append(\"공포가\")\n","            elif np.argmax(logits) == 1:\n","                test_eval.append(\"놀람이\")\n","            elif np.argmax(logits) == 2:\n","                test_eval.append(\"분노가\")\n","            elif np.argmax(logits) == 3:\n","                test_eval.append(\"슬픔이\")\n","            elif np.argmax(logits) == 4:\n","                test_eval.append(\"중립이\")\n","            elif np.argmax(logits) == 5:\n","                test_eval.append(\"행복이\")\n","            elif np.argmax(logits) == 6:\n","                test_eval.append(\"혐오가\")\n","\n","        print(\">> 입력하신 내용에서 \" + test_eval[0] + \" 느껴집니다.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UGF5GFHnzs_g"},"outputs":[],"source":["#질문 무한반복하기! 0 입력시 종료\n","end = 1\n","while end == 1 :\n","    sentence = input(\"하고싶은 말을 입력해주세요 : \")\n","    if sentence == 0 :\n","        break\n","    predict(sentence)\n","    print(\"\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nhj2Rnar0P8t"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}